{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires = 6)\n",
    "n_qubits = 6\n",
    "n_layer_steps = 5\n",
    "n_layers_to_add = 2\n",
    "dim = 2**(n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_gates(n_qubits: int):\n",
    "    \n",
    "    gate_set = [qml.RX, qml.RY, qml.RZ]\n",
    "    chosen_gates = []\n",
    "    for i in range(n_qubits):\n",
    "        chosen_gate = random.choice(gate_set)\n",
    "        chosen_gates.append(chosen_gate)\n",
    "    return chosen_gates\n",
    "\n",
    "def norm(complex_vector: np.array) -> float:\n",
    "    \"\"\"Returns the norm of a complex vector.\n",
    "    \n",
    "    Args:\n",
    "       complex_vector (np.arrray of shape (dim,)):\n",
    "           complex vector with an arbitrary dimension.\n",
    "           \n",
    "       \n",
    "    Returns:\n",
    "        norm (float): norm or magnitude of the complex vector.\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    #define the norm of a complex vector here\n",
    "    norm = np.sqrt(sum([np.square(np.absolute(complex_vector[i])) for i in range(complex_vector.shape[0])]))\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def random_quantum_state(dim: int, amplitude_type: str = 'complex') -> np.array:\n",
    "    \"\"\"Creates a normalized random real or complex vector of a defined\n",
    "    dimension.\n",
    "    \n",
    "    Args:\n",
    "        dim (int): integer number specifying the dimension\n",
    "            of the vector that we want to generate.\n",
    "            \n",
    "        amplitude_type (str): string indicating if you want to create a\n",
    "            vector with 'complex' or 'real' number amplitudes.\n",
    "            \n",
    "    Returns:\n",
    "        (np.array): normalized real or complex vector of the given\n",
    "            dimension.\n",
    "    \"\"\"\n",
    "    #generate an unnormalized complex vector of dimension = dim\n",
    "    if amplitude_type == 'complex':\n",
    "        Z = np.random.random(dim) + np.random.random(dim)*1j\n",
    "    \n",
    "    #generate an unnormalized real vector of dimension = dim\n",
    "    elif amplitude_type == 'real':\n",
    "        Z = np.random.random(dim)\n",
    "    \n",
    "    #normalize the complex vector Z\n",
    "    Z /= norm(Z)\n",
    "    \n",
    "    return Z\n",
    "\n",
    "def density_matrix(target_vector: np.array) -> np.array:\n",
    "    \"\"\"Return the density matrix of a pure state.\n",
    "    \n",
    "    Arguments:\n",
    "        target_vector (np.array): Complex vector array.\n",
    "        \n",
    "    Returns:\n",
    "        (np.array): Density matrix of shape (dim, dim),\n",
    "            where dim is the dimension of the target_vector.\n",
    "    \"\"\"\n",
    "    target_vector_reshape = target_vector.reshape((target_vector.shape[0],1))\n",
    "    density_matrix = target_vector_reshape @ np.transpose(np.conjugate(target_vector_reshape))\n",
    "    \n",
    "    return density_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = random_quantum_state(dim)\n",
    "density_matrix = density_matrix(target_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates for Phase I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.template\n",
    "def apply_layer(gates, weights):\n",
    "    \n",
    "    for i in range(n_qubits):\n",
    "        gates[i](weights[i], wires = i)\n",
    "    \n",
    "    tuples = [(i,i+1) for i in range(n_qubits-1)]\n",
    "\n",
    "    for tup in tuples:\n",
    "        qml.CZ(wires=[tup[0], tup[1]])\n",
    "        \n",
    "@qml.template #template for non-trainable part of the quantum circuit\n",
    "def frozen_layers(frozen_layer_gates, frozen_layer_weights): \n",
    "\n",
    "    for i in range(len(frozen_layer_gates)):\n",
    "        apply_layer(frozen_layer_gates[i], frozen_layer_weights[i])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def trainable_circuit(params):\n",
    "    \n",
    "    #apply frozen layers\n",
    "    frozen_layers(layer_gates, layer_weights)\n",
    "    \n",
    "    #apply trainable layers\n",
    "    new_weights = []\n",
    "    for i in range(n_layers_to_add):\n",
    "        new_weights.append(params[int(i*n_qubits):int((i+1)*n_qubits)])\n",
    "\n",
    "    for i in range(n_layers_to_add):\n",
    "        apply_layer(new_gates[i], new_weights[i])\n",
    "        \n",
    "    wirelist = [i for i in range(n_qubits)]\n",
    "    return qml.expval(qml.Hermitian(density_matrix, wirelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    \n",
    "    return (1.0 - trainable_circuit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003779532166912125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_gates = []\n",
    "layer_weights = []\n",
    "n_layers = 2\n",
    "for i in range(n_layers):\n",
    "    layer_gates.append(set_random_gates(n_qubits))\n",
    "    layer_weights.append(np.random.rand(n_qubits)*2*np.pi)\n",
    "    \n",
    "new_gates = [set_random_gates(n_qubits) for i in range(n_layers_to_add)]\n",
    "params = np.random.rand(n_qubits*n_layers_to_add)*2*np.pi\n",
    "\n",
    "trainable_circuit(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "0.9803189175700198\n",
      "1\n",
      "[array([-1.88500289e-02, -7.63278329e-18,  2.92986693e-01, -4.28631584e-02,\n",
      "        4.25800949e-02, -2.03202408e-01]), array([-0.01885003,  0.11791   ,  0.07449777,  0.42752853,  0.03339696,\n",
      "       -0.08276643])]\n",
      "0.7594185979414175\n",
      "2\n",
      "[array([-1.88500289e-02, -7.63278329e-18,  2.92986693e-01, -4.28631584e-02,\n",
      "        4.25800949e-02, -2.03202408e-01]), array([-0.01885003,  0.11791   ,  0.07449777,  0.42752853,  0.03339696,\n",
      "       -0.08276643]), array([ 1.21485553,  1.65020104, -1.24182455,  0.95286084,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.11813642,  0.10972631, -0.12449923, -0.76713037,  0.02694313,\n",
      "       -0.5171402 ])]\n",
      "0.5230370890092713\n",
      "3\n",
      "[array([-1.88500289e-02, -7.63278329e-18,  2.92986693e-01, -4.28631584e-02,\n",
      "        4.25800949e-02, -2.03202408e-01]), array([-0.01885003,  0.11791   ,  0.07449777,  0.42752853,  0.03339696,\n",
      "       -0.08276643]), array([ 1.21485553,  1.65020104, -1.24182455,  0.95286084,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.11813642,  0.10972631, -0.12449923, -0.76713037,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.25267196, -0.02662812,  0.39235312,  0.38444078,  0.63439665,\n",
      "        1.11155113]), array([-0.01434425,  0.15313149, -0.39482855,  0.02251025, -0.12708225,\n",
      "        0.31694366])]\n",
      "0.21500299776366527\n",
      "4\n",
      "[array([-1.88500289e-02, -7.63278329e-18,  2.92986693e-01, -4.28631584e-02,\n",
      "        4.25800949e-02, -2.03202408e-01]), array([-0.01885003,  0.11791   ,  0.07449777,  0.42752853,  0.03339696,\n",
      "       -0.08276643]), array([ 1.21485553,  1.65020104, -1.24182455,  0.95286084,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.11813642,  0.10972631, -0.12449923, -0.76713037,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.25267196, -0.02662812,  0.39235312,  0.38444078,  0.63439665,\n",
      "        1.11155113]), array([-0.01434425,  0.15313149, -0.39482855,  0.02251025, -0.12708225,\n",
      "        0.31694366]), array([ 0.01075021, -0.01211775, -0.19662557, -0.09183198,  1.34770013,\n",
      "       -0.00946216]), array([ 0.05425855,  0.03336504,  0.26009126,  0.21799258,  0.50105599,\n",
      "       -0.00946216])]\n",
      "0.20329563747807056\n"
     ]
    }
   ],
   "source": [
    "layer_gates = []\n",
    "layer_weights = []\n",
    "cost_list = []\n",
    "for step in range(n_layer_steps):\n",
    "    \n",
    "    new_gates = [set_random_gates(n_qubits) for i in range(n_layers_to_add)]\n",
    "    init_params = np.zeros(n_qubits*n_layers_to_add)\n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "    opt_steps = 100\n",
    "\n",
    "    params = init_params\n",
    "    \n",
    "    for i in range(opt_steps):\n",
    "\n",
    "        params = opt.step(cost, params)\n",
    "    \n",
    "    \n",
    "    print(step)\n",
    "    print(layer_weights)\n",
    "    print(cost(params))\n",
    "    cost_list.append(cost(params))\n",
    "    \n",
    "    trained_weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(n_layers_to_add)]\n",
    "    \n",
    "    layer_gates += new_gates\n",
    "    layer_weights += trained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.88500289e-02, -7.63278329e-18,  2.92986693e-01, -4.28631584e-02,\n",
       "         4.25800949e-02, -2.03202408e-01]),\n",
       " array([-0.01885003,  0.11791   ,  0.07449777,  0.42752853,  0.03339696,\n",
       "        -0.08276643]),\n",
       " array([ 1.21485553,  1.65020104, -1.24182455,  0.95286084,  0.02694313,\n",
       "        -0.5171402 ]),\n",
       " array([ 0.11813642,  0.10972631, -0.12449923, -0.76713037,  0.02694313,\n",
       "        -0.5171402 ]),\n",
       " array([ 0.25267196, -0.02662812,  0.39235312,  0.38444078,  0.63439665,\n",
       "         1.11155113]),\n",
       " array([-0.01434425,  0.15313149, -0.39482855,  0.02251025, -0.12708225,\n",
       "         0.31694366]),\n",
       " array([ 0.01075021, -0.01211775, -0.19662557, -0.09183198,  1.34770013,\n",
       "        -0.00946216]),\n",
       " array([ 0.05425855,  0.03336504,  0.26009126,  0.21799258,  0.50105599,\n",
       "        -0.00946216]),\n",
       " array([0.1354826 , 0.01763158, 0.36127584, 0.10787329, 0.00344715,\n",
       "        0.03953567]),\n",
       " array([ 0.00325754, -0.00696433, -0.12513489,  0.04353759,  0.05932017,\n",
       "        -0.00755341])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_percentage = 0.5\n",
    "partition_size = int(n_layer_steps*n_layers_to_add*partition_percentage)\n",
    "n_partition_weights = partition_size*n_qubits\n",
    "n_sweeps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-1.88500289e-02, -7.63278329e-18,  2.92986693e-01, -4.28631584e-02,\n",
      "        4.25800949e-02, -2.03202408e-01]), array([-0.01885003,  0.11791   ,  0.07449777,  0.42752853,  0.03339696,\n",
      "       -0.08276643]), array([ 1.21485553,  1.65020104, -1.24182455,  0.95286084,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.11813642,  0.10972631, -0.12449923, -0.76713037,  0.02694313,\n",
      "       -0.5171402 ]), array([ 0.25267196, -0.02662812,  0.39235312,  0.38444078,  0.63439665,\n",
      "        1.11155113])]\n",
      "30\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(layer_weights[:5])\n",
    "print(n_partition_weights)\n",
    "print(partition_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainable_layers = layer_gates[:partition_size]\n",
    "#trainable_weights = layer_weights[:partition_size]\n",
    "#weights_flatten = np.concatenate(trainable_weights).ravel()\n",
    "\n",
    "#is going to depend on the part of the circuit\n",
    "@qml.qnode(dev)\n",
    "def trainable_partition(params):\n",
    "    \n",
    "    if partition == 1:\n",
    "        #apply trainable partition\n",
    "        weights = []\n",
    "        for i in range(partition_size):\n",
    "            weights.append(params[int(i*n_qubits):int((i+1)*n_qubits)])\n",
    "        \n",
    "        for i in range(len(layer_gates[:partition_size])):\n",
    "            apply_layer(layer_gates[:partition_size][i], weights[i])\n",
    "            \n",
    "        #apply non-trainable partition\n",
    "        for i in range(len(layer_gates[partition_size:])):\n",
    "            apply_layer(layer_gates[partition_size:][i], layer_weights[partition_size:][i])\n",
    "        \n",
    "    elif partition == 2:\n",
    "        #apply non-trainable partition\n",
    "        for i in range(len(layer_gates[:partition_size])):\n",
    "            apply_layer(layer_gates[:partition_size][i], layer_weights[:partition_size][i])\n",
    "    \n",
    "        #apply trainable partition\n",
    "        weights = []\n",
    "        for i in range(partition_size):\n",
    "            weights.append(params[int(i*n_qubits):int((i+1)*n_qubits)])\n",
    "        \n",
    "        for i in range(len(layer_gates[partition_size:])):\n",
    "            apply_layer(layer_gates[partition_size:][i], weights[i])\n",
    "            \n",
    "    wirelist = [i for i in range(n_qubits)]\n",
    "    return qml.expval(qml.Hermitian(density_matrix, wirelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    \n",
    "    return (1.0 - trainable_partition(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19341886341920778\n",
      "0.1859906609377724\n",
      "0.18510864040715902\n",
      "0.18364257037953735\n"
     ]
    }
   ],
   "source": [
    "for sweep in range(n_sweeps):\n",
    "    \n",
    "    partition = 1\n",
    "    trainable_weights = layer_weights[:partition_size]\n",
    "\n",
    "    init_params = np.concatenate(trainable_weights).ravel()\n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "    opt_steps = 100\n",
    "\n",
    "    params = init_params\n",
    "    \n",
    "    for i in range(opt_steps):\n",
    "\n",
    "        params = opt.step(cost, params)\n",
    "        \n",
    "    trained_weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(partition_size)]\n",
    "    \n",
    "    layer_weights[:partition_size] = trained_weights\n",
    "    \n",
    "    print(cost(params))\n",
    "\n",
    "    partition = 2\n",
    "    trainable_weights = layer_weights[partition_size:]\n",
    "\n",
    "    init_params = np.concatenate(trainable_weights).ravel()\n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "    opt_steps = 100\n",
    "\n",
    "    params = init_params\n",
    "    \n",
    "    for i in range(opt_steps):\n",
    "\n",
    "        params = opt.step(cost, params)\n",
    "        \n",
    "    trained_weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(partition_size)]\n",
    "    \n",
    "    layer_weights[partition_size:] = trained_weights\n",
    "    \n",
    "    print(cost(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete-depth learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def complete_depth_learning(params):\n",
    "    \n",
    "    weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(len(layer_gates))]\n",
    "    \n",
    "    for i in range(len(layer_gates)):\n",
    "        apply_layer(layer_gates[i], weights[i])\n",
    "        \n",
    "    wirelist = [i for i in range(n_qubits)]\n",
    "    return qml.expval(qml.Hermitian(density_matrix, wirelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    \n",
    "    return (1.0 - complete_depth_learning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1860668415207497\n"
     ]
    }
   ],
   "source": [
    "init_params = np.zeros(n_qubits*len(layer_gates))\n",
    "    \n",
    "opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "opt_steps = 200\n",
    "\n",
    "params = init_params\n",
    "\n",
    "for i in range(opt_steps):\n",
    "\n",
    "    params = opt.step(cost, params)\n",
    "\n",
    "print(cost(params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
