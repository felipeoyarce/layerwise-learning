{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#Pennylane\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "#PyTorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device('default.qubit', wires = 6)\n",
    "n_qubits = 6\n",
    "n_layer_steps = 5\n",
    "n_layers_to_add = 2\n",
    "dim = 2**(n_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_gates(n_qubits: int):\n",
    "    \n",
    "    gate_set = [qml.RX, qml.RY, qml.RZ]\n",
    "    chosen_gates = []\n",
    "    for i in range(n_qubits):\n",
    "        chosen_gate = random.choice(gate_set)\n",
    "        chosen_gates.append(chosen_gate)\n",
    "    return chosen_gates\n",
    "\n",
    "def norm(complex_vector: np.array) -> float:\n",
    "    \"\"\"Returns the norm of a complex vector.\n",
    "    \n",
    "    Args:\n",
    "       complex_vector (np.arrray of shape (dim,)):\n",
    "           complex vector with an arbitrary dimension.\n",
    "           \n",
    "       \n",
    "    Returns:\n",
    "        norm (float): norm or magnitude of the complex vector.\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    #define the norm of a complex vector here\n",
    "    norm = np.sqrt(sum([np.square(np.absolute(complex_vector[i])) for i in range(complex_vector.shape[0])]))\n",
    "    \n",
    "    return norm\n",
    "\n",
    "def random_quantum_state(dim: int, amplitude_type: str = 'complex') -> np.array:\n",
    "    \"\"\"Creates a normalized random real or complex vector of a defined\n",
    "    dimension.\n",
    "    \n",
    "    Args:\n",
    "        dim (int): integer number specifying the dimension\n",
    "            of the vector that we want to generate.\n",
    "            \n",
    "        amplitude_type (str): string indicating if you want to create a\n",
    "            vector with 'complex' or 'real' number amplitudes.\n",
    "            \n",
    "    Returns:\n",
    "        (np.array): normalized real or complex vector of the given\n",
    "            dimension.\n",
    "    \"\"\"\n",
    "    #generate an unnormalized complex vector of dimension = dim\n",
    "    if amplitude_type == 'complex':\n",
    "        Z = np.random.random(dim) + np.random.random(dim)*1j\n",
    "    \n",
    "    #generate an unnormalized real vector of dimension = dim\n",
    "    elif amplitude_type == 'real':\n",
    "        Z = np.random.random(dim)\n",
    "    \n",
    "    #normalize the complex vector Z\n",
    "    Z /= norm(Z)\n",
    "    \n",
    "    return Z\n",
    "\n",
    "def density_matrix(target_vector: np.array) -> np.array:\n",
    "    \"\"\"Return the density matrix of a pure state.\n",
    "    \n",
    "    Arguments:\n",
    "        target_vector (np.array): Complex vector array.\n",
    "        \n",
    "    Returns:\n",
    "        (np.array): Density matrix of shape (dim, dim),\n",
    "            where dim is the dimension of the target_vector.\n",
    "    \"\"\"\n",
    "    target_vector_reshape = target_vector.reshape((target_vector.shape[0],1))\n",
    "    density_matrix = target_vector_reshape @ np.transpose(np.conjugate(target_vector_reshape))\n",
    "    \n",
    "    return density_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vector = random_quantum_state(dim)\n",
    "density_matrix = density_matrix(target_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Templates for Phase I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.template\n",
    "def apply_layer(gates, weights):\n",
    "    \n",
    "    for i in range(n_qubits):\n",
    "        gates[i](weights[i], wires = i)\n",
    "    \n",
    "    tuples = [(i,i+1) for i in range(n_qubits-1)]\n",
    "\n",
    "    for tup in tuples:\n",
    "        qml.CZ(wires=[tup[0], tup[1]])\n",
    "        \n",
    "@qml.template #template for non-trainable part of the quantum circuit\n",
    "def frozen_layers(frozen_layer_gates, frozen_layer_weights): \n",
    "\n",
    "    for i in range(len(frozen_layer_gates)):\n",
    "        apply_layer(frozen_layer_gates[i], frozen_layer_weights[i])\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def trainable_circuit(params):\n",
    "    \n",
    "    #apply frozen layers\n",
    "    frozen_layers(layer_gates, layer_weights)\n",
    "    \n",
    "    #apply trainable layers\n",
    "    new_weights = []\n",
    "    for i in range(n_layers_to_add):\n",
    "        new_weights.append(params[int(i*n_qubits):int((i+1)*n_qubits)])\n",
    "\n",
    "    for i in range(n_layers_to_add):\n",
    "        apply_layer(new_gates[i], new_weights[i])\n",
    "        \n",
    "    wirelist = [i for i in range(n_qubits)]\n",
    "    return qml.expval(qml.Hermitian(density_matrix, wirelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    \n",
    "    return (1.0 - trainable_circuit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013567042037599394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_gates = []\n",
    "layer_weights = []\n",
    "n_layers = 2\n",
    "for i in range(n_layers):\n",
    "    layer_gates.append(set_random_gates(n_qubits))\n",
    "    layer_weights.append(np.random.rand(n_qubits)*2*np.pi)\n",
    "    \n",
    "new_gates = [set_random_gates(n_qubits) for i in range(n_layers_to_add)]\n",
    "params = np.random.rand(n_qubits*n_layers_to_add)*2*np.pi\n",
    "\n",
    "trainable_circuit(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "0.7436009708527992\n",
      "1\n",
      "[array([1.20530298e+00, 5.98970338e-01, 7.66347199e-01, 5.20417043e-18,\n",
      "       1.43958492e+00, 1.53924839e+00]), array([ 0.2333933 ,  0.54202741,  0.45715828, -0.08118238,  0.28522425,\n",
      "        0.09180399])]\n",
      "0.7075565784016394\n",
      "2\n",
      "[array([1.20530298e+00, 5.98970338e-01, 7.66347199e-01, 5.20417043e-18,\n",
      "       1.43958492e+00, 1.53924839e+00]), array([ 0.2333933 ,  0.54202741,  0.45715828, -0.08118238,  0.28522425,\n",
      "        0.09180399]), array([-0.37943366,  0.29467347, -0.197845  , -0.09602041,  0.1117119 ,\n",
      "        0.29619841]), array([ 0.11660583,  0.29467347, -0.21511868, -0.09602041,  0.09168672,\n",
      "       -0.00256207])]\n",
      "0.39229445367466587\n",
      "3\n",
      "[array([1.20530298e+00, 5.98970338e-01, 7.66347199e-01, 5.20417043e-18,\n",
      "       1.43958492e+00, 1.53924839e+00]), array([ 0.2333933 ,  0.54202741,  0.45715828, -0.08118238,  0.28522425,\n",
      "        0.09180399]), array([-0.37943366,  0.29467347, -0.197845  , -0.09602041,  0.1117119 ,\n",
      "        0.29619841]), array([ 0.11660583,  0.29467347, -0.21511868, -0.09602041,  0.09168672,\n",
      "       -0.00256207]), array([-0.50110685,  0.06636442,  0.10156093,  1.59666545,  0.14523038,\n",
      "       -0.11610741]), array([-0.01686726, -0.16010603,  0.07784774,  0.06174303, -0.00587617,\n",
      "       -0.2425013 ])]\n",
      "0.35204914365152185\n",
      "4\n",
      "[array([1.20530298e+00, 5.98970338e-01, 7.66347199e-01, 5.20417043e-18,\n",
      "       1.43958492e+00, 1.53924839e+00]), array([ 0.2333933 ,  0.54202741,  0.45715828, -0.08118238,  0.28522425,\n",
      "        0.09180399]), array([-0.37943366,  0.29467347, -0.197845  , -0.09602041,  0.1117119 ,\n",
      "        0.29619841]), array([ 0.11660583,  0.29467347, -0.21511868, -0.09602041,  0.09168672,\n",
      "       -0.00256207]), array([-0.50110685,  0.06636442,  0.10156093,  1.59666545,  0.14523038,\n",
      "       -0.11610741]), array([-0.01686726, -0.16010603,  0.07784774,  0.06174303, -0.00587617,\n",
      "       -0.2425013 ]), array([-0.25486414,  0.26236452,  0.41614368, -0.12534002,  0.0391451 ,\n",
      "        0.01870024]), array([-0.48621249,  0.26236452, -0.03580084, -0.13546174, -0.04371986,\n",
      "       -0.00808908])]\n",
      "0.3290923077895722\n"
     ]
    }
   ],
   "source": [
    "layer_gates = []\n",
    "layer_weights = []\n",
    "cost_list = []\n",
    "for step in range(n_layer_steps):\n",
    "    \n",
    "    new_gates = [set_random_gates(n_qubits) for i in range(n_layers_to_add)]\n",
    "    init_params = np.zeros(n_qubits*n_layers_to_add)\n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "    opt_steps = 100\n",
    "\n",
    "    params = init_params\n",
    "    \n",
    "    for i in range(opt_steps):\n",
    "\n",
    "        params = opt.step(cost, params)\n",
    "    \n",
    "    \n",
    "    print(step)\n",
    "    print(layer_weights)\n",
    "    print(cost(params))\n",
    "    cost_list.append(cost(params))\n",
    "    \n",
    "    trained_weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(n_layers_to_add)]\n",
    "    \n",
    "    layer_gates += new_gates\n",
    "    layer_weights += trained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.20530298e+00, 5.98970338e-01, 7.66347199e-01, 5.20417043e-18,\n",
       "        1.43958492e+00, 1.53924839e+00]),\n",
       " array([ 0.2333933 ,  0.54202741,  0.45715828, -0.08118238,  0.28522425,\n",
       "         0.09180399]),\n",
       " array([-0.37943366,  0.29467347, -0.197845  , -0.09602041,  0.1117119 ,\n",
       "         0.29619841]),\n",
       " array([ 0.11660583,  0.29467347, -0.21511868, -0.09602041,  0.09168672,\n",
       "        -0.00256207]),\n",
       " array([-0.50110685,  0.06636442,  0.10156093,  1.59666545,  0.14523038,\n",
       "        -0.11610741]),\n",
       " array([-0.01686726, -0.16010603,  0.07784774,  0.06174303, -0.00587617,\n",
       "        -0.2425013 ]),\n",
       " array([-0.25486414,  0.26236452,  0.41614368, -0.12534002,  0.0391451 ,\n",
       "         0.01870024]),\n",
       " array([-0.48621249,  0.26236452, -0.03580084, -0.13546174, -0.04371986,\n",
       "        -0.00808908]),\n",
       " array([ 0.1725457 ,  0.03674968,  0.03178398, -0.01024755,  0.01251854,\n",
       "        -0.01268638]),\n",
       " array([ 0.00068052,  0.18855207, -0.00999572, -0.24247306,  0.10701869,\n",
       "        -0.01412737])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_percentage = 0.5\n",
    "partition_size = int(n_layer_steps*n_layers_to_add*partition_percentage)\n",
    "n_partition_weights = partition_size*n_qubits\n",
    "n_sweeps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.20530298e+00, 5.98970338e-01, 7.66347199e-01, 5.20417043e-18,\n",
      "       1.43958492e+00, 1.53924839e+00]), array([ 0.2333933 ,  0.54202741,  0.45715828, -0.08118238,  0.28522425,\n",
      "        0.09180399]), array([-0.37943366,  0.29467347, -0.197845  , -0.09602041,  0.1117119 ,\n",
      "        0.29619841]), array([ 0.11660583,  0.29467347, -0.21511868, -0.09602041,  0.09168672,\n",
      "       -0.00256207]), array([-0.50110685,  0.06636442,  0.10156093,  1.59666545,  0.14523038,\n",
      "       -0.11610741])]\n",
      "30\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(layer_weights[:5])\n",
    "print(n_partition_weights)\n",
    "print(partition_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainable_layers = layer_gates[:partition_size]\n",
    "#trainable_weights = layer_weights[:partition_size]\n",
    "#weights_flatten = np.concatenate(trainable_weights).ravel()\n",
    "\n",
    "#is going to depend on the part of the circuit\n",
    "@qml.qnode(dev)\n",
    "def trainable_partition(params):\n",
    "    \n",
    "    if partition == 1:\n",
    "        #apply trainable partition\n",
    "        weights = []\n",
    "        for i in range(partition_size):\n",
    "            weights.append(params[int(i*n_qubits):int((i+1)*n_qubits)])\n",
    "        \n",
    "        for i in range(len(layer_gates[:partition_size])):\n",
    "            apply_layer(layer_gates[:partition_size][i], weights[i])\n",
    "            \n",
    "        #apply non-trainable partition\n",
    "        for i in range(len(layer_gates[partition_size:])):\n",
    "            apply_layer(layer_gates[partition_size:][i], layer_weights[partition_size:][i])\n",
    "        \n",
    "    elif partition == 2:\n",
    "        #apply non-trainable partition\n",
    "        for i in range(len(layer_gates[:partition_size])):\n",
    "            apply_layer(layer_gates[:partition_size][i], layer_weights[:partition_size][i])\n",
    "    \n",
    "        #apply trainable partition\n",
    "        weights = []\n",
    "        for i in range(partition_size):\n",
    "            weights.append(params[int(i*n_qubits):int((i+1)*n_qubits)])\n",
    "        \n",
    "        for i in range(len(layer_gates[partition_size:])):\n",
    "            apply_layer(layer_gates[partition_size:][i], weights[i])\n",
    "            \n",
    "    wirelist = [i for i in range(n_qubits)]\n",
    "    return qml.expval(qml.Hermitian(density_matrix, wirelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x):\n",
    "    \n",
    "    return (1.0 - trainable_partition(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15779946577370296\n",
      "0.15122895124610236\n",
      "0.1503063459556906\n",
      "0.14993383931630622\n"
     ]
    }
   ],
   "source": [
    "for sweep in range(n_sweeps):\n",
    "    \n",
    "    partition = 1\n",
    "    trainable_weights = layer_weights[:partition_size]\n",
    "\n",
    "    init_params = np.concatenate(trainable_weights).ravel()\n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "    opt_steps = 100\n",
    "\n",
    "    params = init_params\n",
    "    \n",
    "    for i in range(opt_steps):\n",
    "\n",
    "        params = opt.step(cost, params)\n",
    "        \n",
    "    trained_weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(partition_size)]\n",
    "    \n",
    "    layer_weights[:partition_size] = trained_weights\n",
    "    \n",
    "    print(cost(params))\n",
    "\n",
    "    partition = 2\n",
    "    trainable_weights = layer_weights[partition_size:]\n",
    "\n",
    "    init_params = np.concatenate(trainable_weights).ravel()\n",
    "    \n",
    "    opt = qml.GradientDescentOptimizer(stepsize = 0.4)\n",
    "\n",
    "    opt_steps = 100\n",
    "\n",
    "    params = init_params\n",
    "    \n",
    "    for i in range(opt_steps):\n",
    "\n",
    "        params = opt.step(cost, params)\n",
    "        \n",
    "    trained_weights = [params[int(i*n_qubits):int((i+1)*n_qubits)] for i in range(partition_size)]\n",
    "    \n",
    "    layer_weights[partition_size:] = trained_weights\n",
    "    \n",
    "    print(cost(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
